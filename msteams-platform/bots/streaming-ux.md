---
title: Streaming UX in Bots
description: Learn how to enhance the user experience in bots using streaming techniques.
ms.date: 05/07/2024
ms.topic: conceptual
author: v-ypalikila
ms.author: surbhigupta
---

# Streaming UX in Bots

>[!NOTE]
>
> * Streaming UX is only available in one-on-one chats and [public developer preview](../resources/dev-preview/developer-preview-intro.md).

Teams users expect swift and seamless interactions with bots, mirroring the instant responsiveness of chatbots like ChatGPT. However, the current experience falls short due to delays in response generation by underlying Large Language Models (LLMs) or others, leading to user disengagement and a perception of inadequacy.

To bridge this gap, the Streaming UX introduces a dynamic interaction model where bots stream activity and chunks of responses in real-time. This not only aligns with user expectations of promptness but also maintains engagement, transforming the wait time into an informative and interactive experience that enhances the overall utility of Teams bots in daily workflows.

Streaming UX allows bots to send updates to the user while they're generating a response. It can be used to show the user what the bot is doing, such as searching a document or analyzing data, and to show the user the response as the bot is typing it out. Streaming UX can improve the user experience by making the bot seem more responsive, performative, and transparent.

Streaming UX has two types of updates:

* **Informative updates**: Informative updates are shown as a blue progress bar at the bottom of the chat, and they tell the user what the bot is doing before it has a response ready.

* **Response streaming**: Response streaming is shown as a typing indicator, and it shows the user the response as the bot is generating it.

## Enable streaming in bots

To enable streaming in bots, follow these steps:

1. ***Start streaming***: Initiate the streaming process to begin sharing content.

    ```json
    // Ex: A bot sends the second request with content && the content is informative loading message.
    
        POST /conversations/<conversationId>/activities HTTP/1.1 {
        "type": "typing",
        " serviceurl": "<https://smba.trafficmanager.net/amer/> ",
        "channelId": "msteams",
        "from": {
           "id": "<botId>",
            "name": "BotName>"
          },
          "conversation": {
            "conversationType": "personal",
            "id : (conversationId>"
          },
          "recipient": {
            "id": "recipientId>",
            "name": "<recipientName>",
            "aadObjectId": "<recipient aad objecID>"
          },
        "locale": "en-US"
         "text": "Searching through documents.", // First informative loading message.
         "channelData": { 
         "streamType": "informative", // informative or streaming(name needs to be finalized); default: streaming.
            "streamSequence": 1 // (required) incremental integer; must be present for any streaming request.
         }
    } 
    201 created {a-0000l} // return activity id
    ```

2. ***Provide informative updates***: Offer insights into the bot's current actions, such as **Scanning through documents** or **Summarizing Content**. These updates should occur before the bot generates its final response.

   ```json
    // Ex: A bot sends the second request with content && the content is informative loading message.
    POST /conversations/<conversationId>/activities HTTP/1.1 
    {
      "type": "typing",
      " serviceurl": "<https://smba.trafficmanager.net/amer/> ",
      "channelId": "msteams",
      "from": {
        "id": "<botId>",
        "name": "BotName>"
      },
      "conversation": {
        "conversationType": "personal",
        "id : <conversationId>"
      },
      "recipient": {
        "id": "recipientId>",
        "name": "<recipientName>",
        "aadObjectId": "<recipient aad objecID>"
      },
      "locale": "en -US",
      "text ": "Searching
      through emails...", // (required) second informative loading message.
      "channelData": {
        "streamld ": "a-0000l", // (required) must be present for any subsequence request after the first chunk.
        "streamType": "informative",
        "streamSequence": 2, // (required) incremental integer; must be present for any streaming request.
      }
    } 
    200 0K

   ```

3. ***Switch to response streaming***: Transition to response streaming once the bot is ready to generate the final message. Each update should include the latest version of the final message, appending new tokens generated by the LLM to the previous message content.

   ```json
   // Ex: A bot sends the second request with content && the content is informative loading message.
    POST /conversations/<conversationId>/activities HTTP/1.1
    {
     "type": "typing",
     " serviceurl" : "https://smba.trafficmanager.net/amer/ ",
     "channelId": "msteams",
     "from": {
        "id": "<botId>",
        "name": "BotName>"
       },
     "conversation": {
        "conversationType": "personal",
        "id : (conversationId>"
        },
     "recipient": {
      "id" : "recipientId>",
      "name": "<recipientName>",
      "aadObjectId": "<recipient aad objecID>"
      },
      "locale": "en-US" ,
      "text ": "A brown fox" // (required) first streaming content.
      "channelData": {
        "streamld ": "a-0000l", // (required) must be present for any subsequence request after the first chunk.
        "streamType": "streaming",
        "streamSequence": 3, // (required) incremental integer; must be present for any streaming request.
       }
    }
    200 0K
   ```

   ```json
   // Ex: A bot sends the second request with content && the content is informative loading message.
    POST /conversations/<conversationId>/activities HTTP/1.1
    {
     "type": "typing",
     " serviceurl" : "https://smba.trafficmanager.net/amer/ ",
     "channelId": "msteams",
     "from": {
        "id": "<botId>",
        "name": "BotName>"
       },
     "conversation": {
        "conversationType": "personal",
        "id : (conversationId>"
        },
     "recipient": {
      "id" : "recipientId>",
      "name": "<recipientName>",
      "aadObjectId": "<recipient aad objecID>"
      },
      "locale": "en-US" ,
      "text ": "A brown fox jumped over the fence.", // (required) second streaming content.
      "channelData": {
        "streamld ": "a-0000l", // (required) must be present for any subsequence request after the first chunk.
        "streamType": "streaming",
        "streamSequence": 4, // (required) incremental integer; must be present for any streaming request.
       }
    }
    200 0K
   ```

4. ***End streaming and send the final message***: Conclude the streaming with an end signal and deliver the final message and its contents to the user.

    ```json
       // Ex: A bot sends the second request with content && the content is informative loading message.
        POST /conversations/<conversationId>/activities HTTP/1.1
        {
         "type": "message",
         " serviceurl" : "https://smba.trafficmanager.net/amer/ ",
         "channelId": "msteams",
         "from": {
            "id": "<botId>",
            "name": "BotName>"
           },
         "conversation": {
            "conversationType": "personal",
            "id : (conversationId>"
            },
         "recipient": {
          "id" : "recipientId>",
          "name": "<recipientName>",
          "aadObjectId": "<recipient aad objecID>"
          },
          "locale": "en-US" ,
          "text ": "A brown fox jumped over the fence.", // (required) final full streamed content.
          "channelData": {
            "streamld ": "a-0000l", // (required) must be present for any subsequence request after the first chunk.
            "streamType": "final",
           }
        }
        200 0K
       ```

## Limitations

* Ensure no attachments are included during streaming.
* Maintain only one stream per thread.
* Handle other potential errors gracefully.

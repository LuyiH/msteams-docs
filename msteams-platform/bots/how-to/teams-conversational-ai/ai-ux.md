---
title: Custom engine agent user experience
description: Learn about the user experience for custom engine agent
ms.localizationpriority: medium
ms.topic: overview
ms.author: surbhigupta
ms.date: 09/27/2024
---

# Build custom engine agent user experience

A custom engine agent is designed to transform the way we interact with systems. For user experience (UX) designers and developers, creating an outstanding user experience is crucial to fully harness its potential. This article details the necessary steps, principles, and considerations for crafting intuitve, user-centered interfaces that seamlessly integrate AI capabilities.

The key objectives to building a great user experience involves simplifying complex tasks, enhancing productivity, enabling personalized experience through adaptive learning.

## What is a custom engine agent?

A custom engine agent encompasses the following features that aid its functionality and integration within the Microsoft ecosystem:

- **Generative AI integration**: Utilizes advanced AI models to facilitate natural language processing and interaction.
- **Bots**: Extend or build bots to utilize the LLM and generative AI to provide high quality chat bots experience.
- **Customizable orchestration**: Offers extensive customization options, allowing developers to tailor the custom agent behavior and responses to specific use cases.

To meet this goal, you must follow some mandatory and recommended steps and requirements.

## Ensure mandatory requirements for custom engine agent

The following requirements are mandatory for building the custom engine agent UX:

- [Update the app manifest to connect the bot ID with the custom engine agent node](#update-the-app-manifest-for-custom-engine-agent).

- [Stream the custom engine agent response to the user](#stream-the-custom-engine-agent-response-to-the-user).

- [Ensure the custom engine agent response contains citations](#ensure-the-custom-engine-agent-response-contains-citations).

- [Ensure the custom engine agent response contains an AI Label](#ensure-the-custom-engine-agent-response-contains-an-ai-label).

- [Ensure that the custom engine agent is an intelligent conversational bot](#ensure-that-the-custom-engine-agent-is-an-intelligent-conversational-bot).

- [Ensure that the custom engine agent offers zero prompts or welcome card](#ensure-that-the-custom-engine-agent-offers-zero-prompts-or-welcome-card).

### Update the app manifest for custom engine agent

You must update the custom engine agent app manifest to define specific properties and configurations that characterize its capabilities and behavior.

Add the `botID` property to the `copilotExtension1 node in the manifest.

```json
"bots": [ 

    { 

      "botId": "bd5b01bf-03ac-4909-99dc-41c6e88451ff", 

      // ... existing bot node fields 

      "registrationInfo": { 

        "source": "microsoftCopilotStudio", 

        "environment": "7211551f-2b82-e1af-9013-002025094241", 

        "schemaName": "cr4c9_copilot", // New, specific to copilot studio bots 

        "clusterCategory": "preprod" // New, specific to copilot studio bots 

      } 

    } 

  ], 

  "copilotExtensions": { 

    "customEngineCopilots": [{ // New 

      "type": "bot", // Only option 

      "id": "bd5b01bf-03ac-4909-99dc-41c6e88451ff"  // Validated against bots node 

    }] 

  }, 
```

### Stream the custom engine agent response to the user

A custom engine agent uses a large language model (LLM) to handle complex user requests, which can cause a delay in generating responses. To prevent this delay from being noticeable to users, custom engine agent must stream its responses, making them appear fast despite the processing time.

To stream the response:

- Informative updates: Send information on the sub-steps the agent as the response is being generated before it sends the final response.
- Response streaming: Sending the user intermediate states of the final response while the LLM creates its full response.

You can use one of the following to stream the resposne:

- Use Teams AI Library to add streaming to the agent.
- Call the bot framework APIs directly for streaming.

### Ensure the custom engine agent response contains citations

Users must know the sources a custom engine agent uses to generate its final response. Identifying these resources allows users to validate and trust the agent's responses.

You can use one of the following to include citations for the resources used by the agent:

- Use Teams AI Library citations module.
- Incorporate citations into the Bot Framework API calls.

### Ensure the custom engine agent response contains an AI Label

A custom engine agent must clearly identify that a chatbot uses AI. Informing users that a response is AI-generated helps build trust in the bot's capabilities. To ensure this, a custom engine agent must include a flag in each AI-generated response to indicate it was generated by AI. This flag automatically adds an AI-Label next to the response.

You can use one of the following to include AI Label in the agent's response:

- Use Teams AI Library, which add the AI Label to all AI-generated messages automatically.
- Set the flag in the Bot Framework API for message activities.

### Ensure that the custom engine agent is an intelligent conversational bot

A custom engine agent must track a conversation's context and history to provide an intelligent experience. The bot must meet the user's expectation by being aware of the conversation's context and allowing them to refer to previous messages and responses.

You can use one of the following to ensure intelligent context-based conversation:

- Use Teams AI Library, which manages and passes conversational history and context to the LLM.
- Use Bot Framework API:

  - **Manage context and conversation history**: Ensure that the agent can track the context and conversation history.
  - **Identify conversation location**: Ensure the agent is aware of platform the conversation is occurring in, such as on Teams, copilot.com, in a meeting side-pane, or a group chat.
  - **Store and pass conversation history**: Determine means of storage and pass some extent of the conversation history to the agent.
  - **Understand user references**: Ensure that when a user sends a message, the agent must understand what the user is referring to using the LLM and recent conversation history. The agent mustn't need the user to reestablish context with every message.

### Ensure that the custom engine agent offers zero prompts or welcome card

A custom engine agent must assist users by offering prompt suggestions on how to best utilize the agent. This will help users overcome challenges not only during their initial use but also in subsequent interactions with the agent.

- **Prompt starters**: Prompts starters are the initial prompts that users see when a custom engine agent is added to a new conversation, such as starting a new one-on-one chat, a new session, or adding it to a group chat. These prompts should be tailored to the user's context and the specific conversation thread.
- **Contextual prompts**: Contextual prompts are dynamic recommendations offered by a custom engine agent during a user interaction. These prompts surface via contextual flyouts, for instance, the "View Prompts" flyout in one-on-one chats and the @mention flyout in group chats and channels. The suggestions are consistently updated to remain pertinent to the ongoing conversation between the user and the agent.
- **Suggested action**: Suggested actions are prompts that users see as pills above the compose box in 1:1 chats and as action buttons in the message footer in group chats. These actions are suggestions that the user may want to take in response to the agent’s message. The prompts are sent along with the agent’s response and should be customized to match the content of the response.

## Best practices for custom engine agent

The following best practices can help enhance the overall effectiveness of a custom engine agent.

- Enable Teams Azure AD (AAD) single sign-on (SSO)
- Build understanding for conversational history and context
- Develop responses with feedback buttons so that the app ingests feedback
- Offer dynamic and contextual suggestion prompts

### Ensure that bot reponses contain feedback buttons and app ingests user feedback

Develop the capability in the custom engine agent to receive user feedback. This could enable the collection of valuable insights from users, which can be analyzed to identify areas for improvement. By incorporating this feedback, the bot's responses can be continuously refined and enhanced, leading to a more effective and user-friendly interaction experience.

To collect the user feedback, you must:

- Provide feedback buttons with every response
- Provide the feedback received from the user to the bot
- Use the feedback to improve the quality of bot responses

You can use one of the following to ensure intelligent context-based conversation:

- Use Teams AI Library to add the feedback button property to the AI module. This property adds a feedback button to each AI-generated message automatically.
- Use the feedback flag in the Bot Framework API to add the feedback button for each message.

## Next step

## See also
